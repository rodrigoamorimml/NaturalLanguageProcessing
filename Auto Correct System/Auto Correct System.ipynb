{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Auto correct system is an application that changes mispelled words into the correct ones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook I'll show how to implement an Auto Correct System that its very usefull.\n",
    "# This auto correct system only search for spelling erros, not contextual errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "*The implementation can be divided into 4 steps:*\n",
    "\n",
    "[1]. **Identity a mispelled word.**\n",
    "\n",
    "[2]. **Find strings n Edit Distance away**\n",
    "\n",
    "[3]. **Filter Candidates** (*as Real Words that are spelled correct*)\n",
    "\n",
    "[4]. **Calculate Word Probabilities.** (*Choose the most likely cadidate to be the replacement*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Identity a mispelled Word\n",
    "\n",
    "*To identify if a word was mispelled, you can check if the word is in the dictionary / vocabulary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word: congratulations is in the vocab\n",
      "The word: my is in the vocab\n",
      "The word: deah isn't in the vocabulary\n"
     ]
    }
   ],
   "source": [
    "vocab = ['dean','deer','dear','fries','and','coke', 'congratulations', 'my']\n",
    "\n",
    "word_test = 'Congratulations my deah'\n",
    "word_test = word_test.lower()\n",
    "word_test = word_test.split()\n",
    "\n",
    "for word in word_test:\n",
    "    if word in vocab:\n",
    "        print(f'The word: {word} is in the vocab')\n",
    "    else:\n",
    "        print(f\"The word: {word} isn't in the vocabulary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Find strings n Edit Distance Away\n",
    "\n",
    "*Edit is a operation performed on a string to change into another string. Edit distance count the number of these operations*\n",
    "\n",
    "*So **n Edit Distance** tells you how many operations away one string is from another.*\n",
    "\n",
    "*For this application we'll use the Levenshtein Distance value's cost, where this edit value are:*\n",
    "\n",
    "* **Insert** - Operation where you insert a letter, the cost is equal to 1.\n",
    "\n",
    "* **Delete** - Operation where you delete a letter, the cost is equal to 1.\n",
    "\n",
    "* **Replace** - Operation where you replace one letter to another, the cost is equal to 2.\n",
    "\n",
    "* **Switch** - Operation where you swap  2 **adjacent** letters\n",
    "\n",
    "*Also we'll use the Minimum Edit Distance which is the minimum number of edits needed to transform 1 string into the other, for that we are using n = 2 and the Dynamic Programming algorithm. ( will be explained when it is implemented ) for evaluate our model*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'dear']\n",
      "['d', 'ear']\n",
      "['de', 'ar']\n",
      "['dea', 'r']\n",
      "['dear', '']\n"
     ]
    }
   ],
   "source": [
    "# To implement this operations we need to split the word into 2 parts in all possible ways\n",
    "\n",
    "word = 'dear'\n",
    "\n",
    "split_word = [[word[:i], word[i:]] for i in range(len(word) + 1)]\n",
    "for i in split_word:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ear']\n",
      "['dar']\n",
      "['der']\n",
      "['dea']\n"
     ]
    }
   ],
   "source": [
    "# The delete operation need to delete each possible letter from the original word.\n",
    "\n",
    "delete_operation = [[L + R[1:]] for L, R in split_word if R ]\n",
    "\n",
    "for i in delete_operation:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first insert operations: \n",
      "\n",
      "adear\n",
      "bdear\n",
      "cdear\n",
      "ddear\n",
      "the last insert operations:\n",
      "\n",
      "dearw\n",
      "dearx\n",
      "deary\n",
      "dearz\n"
     ]
    }
   ],
   "source": [
    "# The same way the insert operation need to add each possible letter from the vocab to the original word\n",
    "\n",
    "letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "insert_operation = [L + s + R for L, R in split_word for s in letters]\n",
    "\n",
    "c = 0\n",
    "print('the first insert operations: ')\n",
    "print()\n",
    "for i in insert_operation:\n",
    "    print(i)\n",
    "    c += 1\n",
    "    if c == 4:\n",
    "        break\n",
    "c = 0\n",
    "print('the last insert operations:')\n",
    "print()\n",
    "for i in insert_operation:\n",
    "    c += 1\n",
    "    if c > 126:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edar']\n",
      "['daer']\n",
      "['dera']\n"
     ]
    }
   ],
   "source": [
    "# Switch Operation\n",
    "\n",
    "switch_operation = [[L[:-1] + R[0] + L[-1] + R[1:]] for L, R in split_word if R and L]\n",
    "\n",
    "for i in switch_operation:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first replace operations: \n",
      "\n",
      "aear\n",
      "bear\n",
      "cear\n",
      "dear\n",
      "the last replace operations:\n",
      "\n",
      "deaw\n",
      "deax\n",
      "deay\n",
      "deaz\n"
     ]
    }
   ],
   "source": [
    "# Replace Operation\n",
    "\n",
    "letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "replace_operation = [L + s + (R[1:] if len(R) > 1 else '') for L, R in split_word if R for s in letters ] \n",
    "\n",
    "c = 0\n",
    "print('the first replace operations: ')\n",
    "print()\n",
    "for i in replace_operation:\n",
    "    print(i)\n",
    "    c += 1\n",
    "    if c == 4:\n",
    "        break\n",
    "\n",
    "c = 0\n",
    "print('the last replace operations:')\n",
    "print()\n",
    "for i in replace_operation:\n",
    "    c += 1\n",
    "    if c > 100:\n",
    "        print(i)\n",
    "\n",
    "        \n",
    "# Remember that at the end we need to remove the word it self\n",
    "replace_operation = set(replace_operation)\n",
    "replace_operation.discard('dear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Filter Candidates\n",
    "\n",
    "*We only want to consider real and correctly spelled words form the candidate lists, so we need to compare to a know dictionary.*\n",
    "\n",
    "*If the string does not appears in the dict, remove from the candidates, this way resulting in a list of actual words only*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deer', 'dean']\n"
     ]
    }
   ],
   "source": [
    "vocab = ['dean','deer','dear','fries','and','coke', 'congratulations', 'my']\n",
    "\n",
    "# for example we can use the replace operations words to filter in our vocab\n",
    "\n",
    "filtered_words = [word for word in replace_operation if word in vocab]\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate the words probabilities\n",
    "\n",
    "*We need to find the most likely word from the cadidate list, to calculate the probability of a word in the \n",
    "sentence we need to first calculate the word frequencies, also we want to count the total number of word in the body of texts\n",
    "or corpus.*\n",
    "\n",
    "*So we compute the probability that each word will appear if randomly selected from the corpus of words.*\n",
    "\n",
    "$$P(w_i) = \\frac{C(w_i)}{M} \\tag{Eq 01}$$\n",
    "*where*\n",
    "\n",
    "$C(w_i)$ *is the total number of times $w_i$ appears in the corpus.*\n",
    "\n",
    "$M$ *is the total number of words in the corpus.*\n",
    "\n",
    "*For example, the probability of the word 'am' in the sentence **'I am happy because I am learning'** is:*\n",
    "\n",
    "$$P(am) = \\frac{C(w_i)}{M} = \\frac {2}{7} \\tag{Eq 02}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the we know the four steps of the Auto Correct System, we can start to implement it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The first thing to do is the data pre processing, for this example we'll use the file called **'shakespeare.txt'** this file can be found in the directory.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(filename):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        A file_name which is found in the current directory. We just have to read it in. \n",
    "    Output: \n",
    "        words: a list containing all the words in the corpus (text file you read) in lower case. \n",
    "    \"\"\"\n",
    "    \n",
    "    words = []\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    words = re.findall(r'\\w+', text)\n",
    "    words = [word.lower() for word in words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary has 6116 unique words.\n"
     ]
    }
   ],
   "source": [
    "words = process_data('shakespeare.txt')\n",
    "vocab = set(words) # eliminate duplicates \n",
    "\n",
    "print(f'The vocabulary has {len(vocab)} unique words.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The second step, we need to count the frequency of every word in the dictionary to later calculate the probabilities*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6116 key par values\n",
      "The count for the word 'thee' is 240\n"
     ]
    }
   ],
   "source": [
    "def get_count(word):\n",
    "    '''\n",
    "    Input:\n",
    "        word_l: a set of words representing the corpus. \n",
    "    Output:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    '''\n",
    "    word_count_dict = {}\n",
    "    \n",
    "    word_count_dict = Counter(word)\n",
    "    \n",
    "    return word_count_dict\n",
    "\n",
    "\n",
    "word_count_dict = get_count(words)\n",
    "print(f'There are {len(word_count_dict)} key par values')\n",
    "print(f\"The count for the word 'thee' is {word_count_dict.get('thee',0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now we must calculate the probability that each word appears using the (eq 01):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of probs is 6116\n",
      "P('thee') is 0.0045\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_probs(word_count_dict):\n",
    "    '''\n",
    "    Input:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    Output:\n",
    "        probs: A dictionary where keys are the words and the values are the probability that a word will occur. \n",
    "    '''\n",
    "    \n",
    "    probs = {}\n",
    "    total_words = 0\n",
    "    \n",
    "    for word, value in word_count_dict.items():\n",
    "        total_words += value  # we add the quantity of each word appears\n",
    "        \n",
    "    for word, value in word_count_dict.items():\n",
    "        probs[word] = value / total_words\n",
    "        \n",
    "    \n",
    "    return probs\n",
    "\n",
    "probs = get_probs(word_count_dict)\n",
    "print(f\"Length of probs is {len(probs)}\")\n",
    "print(f\"P('thee') is {probs['thee']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now, that we have computed $P(w_i)$ for all the words in the corpus, we'll write the functions such as delete, insert, switch and replace to manipulate strings so that we can edit the erroneous strings and return the right spellings of the words.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word cans, \n",
      "split_word = [['', 'cans'], ['c', 'ans'], ['ca', 'ns'], ['can', 's']], \n",
      "delete_word = ['ans', 'cns', 'cas', 'can']\n"
     ]
    }
   ],
   "source": [
    "def delete_letter(word, verbose = False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the string/word for which you will generate all possible words \n",
    "                in the vocabulary which have 1 missing character\n",
    "    Output:\n",
    "        delete_l: a list of all possible strings obtained by deleting 1 character from word\n",
    "    '''\n",
    "    \n",
    "    delete = []\n",
    "    split_word = []\n",
    "    \n",
    "    split_word = [[word[:i], word[i:]] for i in range(len(word))]\n",
    "    \n",
    "    delete = [L + R[1:] for L, R in split_word if R]\n",
    "    \n",
    "    if verbose: print(f\"input word {word}, \\nsplit_word = {split_word}, \\ndelete_word = {delete}\")\n",
    "\n",
    "    return delete\n",
    "\n",
    "delete_word = delete_letter(word=\"cans\",\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = eta \n",
      "split = [['', 'eta'], ['e', 'ta'], ['et', 'a']] \n",
      "switch = ['tea', 'eat']\n"
     ]
    }
   ],
   "source": [
    "def switch_letter(word, verbose = False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: input string\n",
    "     Output:\n",
    "        switches: a list of all possible strings with one adjacent charater switched\n",
    "    ''' \n",
    "    \n",
    "    switch = []\n",
    "    split_word = []\n",
    "    \n",
    "    split_word = [[word[:i], word[i:]] for i in range(len(word))]\n",
    "    \n",
    "    switch = [L[:-1] + R[0] + L[-1] + R[1:] for L, R in split_word if L and R]\n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit = {split_word} \\nswitch = {switch}\") \n",
    "\n",
    "    return switch\n",
    "\n",
    "switch_word_l = switch_letter(word=\"eta\",\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = can \n",
      "split = [('', 'can'), ('c', 'an'), ('ca', 'n')] \n",
      "replace ['aan', 'ban', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan']\n"
     ]
    }
   ],
   "source": [
    "def replace_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        replaces: a list of all possible strings where we replaced one letter from the original word. \n",
    "    ''' \n",
    "    \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    replace = []\n",
    "    split_word = []\n",
    "    \n",
    "\n",
    "    split_word = [(word[:i], word[i:]) for i in range(len(word))]\n",
    "    \n",
    "    replace = [L + s + (R[1:] if len(R) > 1 else '') for L, R in split_word if R for s in letters ]\n",
    "    \n",
    "    # we need to remove the actual word from the list\n",
    "    replace = set(replace)\n",
    "    replace.discard(word)\n",
    "\n",
    "   \n",
    "    \n",
    "    replace = sorted(list(replace)) # turn the set back into a list and sort it, for easier viewing\n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit = {split_word} \\nreplace {replace}\")   \n",
    "    \n",
    "    return replace\n",
    "\n",
    "replace_l = replace_letter(word='can',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word at \n",
      "split = [('', 'at'), ('a', 't'), ('at', '')] \n",
      "insert = ['aat', 'bat', 'cat', 'dat', 'eat', 'fat', 'gat', 'hat', 'iat', 'jat', 'kat', 'lat', 'mat', 'nat', 'oat', 'pat', 'qat', 'rat', 'sat', 'tat', 'uat', 'vat', 'wat', 'xat', 'yat', 'zat', 'aat', 'abt', 'act', 'adt', 'aet', 'aft', 'agt', 'aht', 'ait', 'ajt', 'akt', 'alt', 'amt', 'ant', 'aot', 'apt', 'aqt', 'art', 'ast', 'att', 'aut', 'avt', 'awt', 'axt', 'ayt', 'azt', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz']\n",
      "Number of strings output by insert_letter('at') is 78\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def insert_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        inserts: a set of all possible strings with one new letter inserted at every offset\n",
    "    ''' \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    insert = []\n",
    "    split_word = []\n",
    "    \n",
    "\n",
    "    split_word = [(word[:i], word[i:]) for i in range(len(word) + 1 )]\n",
    "    insert = [L + s + R for L, R in split_word  for s in letters]\n",
    "\n",
    "\n",
    "\n",
    "    if verbose: print(f\"Input word {word} \\nsplit = {split_word} \\ninsert = {insert}\")\n",
    "    \n",
    "    return insert\n",
    "\n",
    "insert = insert_letter('at', True)\n",
    "print(f\"Number of strings output by insert_letter('at') is {len(insert)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now that we have implemented the string manipulations, we'll create two functions that, given a string, will return all the possible single and double edits on that string. These will be `edit_one_letter()` and `edit_two_letters()`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word: at \n",
      "edit_one \n",
      "['a', 'aa', 'aat', 'ab', 'abt', 'ac', 'act', 'ad', 'adt', 'ae', 'aet', 'af', 'aft', 'ag', 'agt', 'ah', 'aht', 'ai', 'ait', 'aj', 'ajt', 'ak', 'akt', 'al', 'alt', 'am', 'amt', 'an', 'ant', 'ao', 'aot', 'ap', 'apt', 'aq', 'aqt', 'ar', 'art', 'as', 'ast', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aut', 'av', 'avt', 'aw', 'awt', 'ax', 'axt', 'ay', 'ayt', 'az', 'azt', 'bat', 'bt', 'cat', 'ct', 'dat', 'dt', 'eat', 'et', 'fat', 'ft', 'gat', 'gt', 'hat', 'ht', 'iat', 'it', 'jat', 'jt', 'kat', 'kt', 'lat', 'lt', 'mat', 'mt', 'nat', 'nt', 'oat', 'ot', 'pat', 'pt', 'qat', 'qt', 'rat', 'rt', 'sat', 'st', 't', 'ta', 'tat', 'tt', 'uat', 'ut', 'vat', 'vt', 'wat', 'wt', 'xat', 'xt', 'yat', 'yt', 'zat', 'zt']\n",
      "\n",
      "The type of the returned object should be a set <class 'set'>\n",
      "Number of outputs from edit_one_letter('at') is 129\n"
     ]
    }
   ],
   "source": [
    "def edit_one_letter(word, allow_switches = True): # The 'switch' function is a less common edit function, \n",
    "                                                # so  will be selected by an \"allow_switches\" input argument.\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: the string/word for which we will generate all possible wordsthat are one edit away.\n",
    "    Output:\n",
    "        edit_one_set: a set of words with one possible edit. Please return a set. and not a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    edit_one_set = set()\n",
    "    all_word, words = [] , []\n",
    "    \n",
    "    words.append(insert_letter(word))\n",
    "    words.append(delete_letter(word))\n",
    "    words.append(replace_letter(word))\n",
    "    if allow_switches == True:\n",
    "        words.append(switch_letter(word))\n",
    "        \n",
    "    for i in words:\n",
    "        for each_word in i:\n",
    "            if each_word == word: # we exclude the word it self\n",
    "                continue\n",
    "            all_word.append(each_word)\n",
    "    \n",
    "    edit_one_set = set(all_word)\n",
    "    \n",
    "    return edit_one_set\n",
    "\n",
    "tmp_word = \"at\"\n",
    "tmp_edit_one_set = edit_one_letter(tmp_word)\n",
    "# turn this into a list to sort it, in order to view it\n",
    "tmp_edit_one = sorted(list(tmp_edit_one_set))\n",
    "\n",
    "print(f\"input word: {tmp_word} \\nedit_one \\n{tmp_edit_one}\\n\")\n",
    "print(f\"The type of the returned object should be a set {type(tmp_edit_one_set)}\")\n",
    "print(f\"Number of outputs from edit_one_letter('at') is {len(edit_one_letter('at'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_two_letters(word, allow_switches = True):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        edit_two_set: a set of strings with all possible two edits\n",
    "    '''\n",
    "    \n",
    "    edit_two_set = set()\n",
    "    \n",
    "    \n",
    "    if allow_switches == True:\n",
    "        first_edit = edit_one_letter(word)\n",
    "    \n",
    "    else:\n",
    "        first_edit = edit_one_letter(word, allow_switches = False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    first_edit = set(first_edit)\n",
    "    second_edit = []\n",
    "    final_edit = []\n",
    "    \n",
    "    if allow_switches == True:\n",
    "        for each_word in first_edit:\n",
    "            second_edit.append(edit_one_letter(each_word))\n",
    "        for i in second_edit:\n",
    "               for each_word in i:\n",
    "                    final_edit.append(each_word)\n",
    "        edit_two_set = set(final_edit)\n",
    "    \n",
    "    else:\n",
    "        for each_word in first_edit:\n",
    "            second_edit.append(edit_one_letter(each_word, allow_switches = False))\n",
    "        for i in second_edit:\n",
    "               for each_word in i:\n",
    "                    final_edit.append(each_word)\n",
    "        edit_two_set = set(final_edit)\n",
    "   \n",
    "    \n",
    "    return edit_two_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings with edit distance of two: 2654\n",
      "First 10 strings ['', 'a', 'aa', 'aaa', 'aab', 'aac', 'aad', 'aae', 'aaf', 'aag']\n",
      "Last 10 strings ['zv', 'zva', 'zw', 'zwa', 'zx', 'zxa', 'zy', 'zya', 'zz', 'zza']\n",
      "The data type of the returned object should be a set <class 'set'>\n",
      "Number of strings that are 2 edit distances from 'at' is 7154\n"
     ]
    }
   ],
   "source": [
    "tmp_edit_two_set = edit_two_letters(\"a\")\n",
    "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
    "print(f\"Number of strings with edit distance of two: {len(tmp_edit_two_l)}\")\n",
    "print(f\"First 10 strings {tmp_edit_two_l[:10]}\")\n",
    "print(f\"Last 10 strings {tmp_edit_two_l[-10:]}\")\n",
    "print(f\"The data type of the returned object should be a set {type(tmp_edit_two_set)}\")\n",
    "print(f\"Number of strings that are 2 edit distances from 'at' is {len(edit_two_letters('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now we will use the `edit_two_letters` function to get a set of all the possible 2 edits on our word. We will then use those strings to get the most probable word we meant to substitute our word typing suggestion.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corrections(word, probs, vocab, n=2, verbose = False):\n",
    "    '''\n",
    "    Input: \n",
    "        word: a user entered string to check for suggestions\n",
    "        probs: a dictionary that maps each word to its probability in the corpus\n",
    "        vocab: a set containing all the vocabulary\n",
    "        n: number of possible word corrections you want returned in the dictionary\n",
    "    Output: \n",
    "        n_best: a list of tuples with the most probable n corrected words and their probabilities.\n",
    "    '''\n",
    "    \n",
    "    suggestions = []\n",
    "    n_best = []\n",
    "    \n",
    "    # look if the word exist in the vocab, if doesn't, the edit_one_letter fuction its used, if any of the letter created \n",
    "    # exists in the vocab, take the two letter edit function, if any of this situations are in the vocab, take the input word\n",
    "    suggestions = list((word in vocab) or (edit_one_letter(word).intersection(vocab)) or (edit_two_letter(word).intersection(vocab)) or word)\n",
    "    \n",
    "\n",
    "    n_best= [[word, probs[word]] for word in (suggestions)]  # make a list with the possible word and probability.\n",
    "    \n",
    "    \n",
    "    if verbose: print(\"entered word = \", word, \"\\nsuggestions = \", set(suggestions))\n",
    "\n",
    "    return n_best\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered word =  dys \n",
      "suggestions =  {'days', 'dye'}\n",
      "word 0: days, probability 0.000410\n",
      "word 1: dye, probability 0.000019\n",
      "The highest score for all the candidates is the word days\n"
     ]
    }
   ],
   "source": [
    "my_word = 'dys' \n",
    "tmp_corrections = get_corrections(my_word, probs, vocab, 2, verbose=True) # keep verbose=True\n",
    "for i, word_prob in enumerate(tmp_corrections):\n",
    "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n",
    "\n",
    "print(f'The highest score for all the candidates is the word {tmp_corrections[np.argmax(word_prob)][0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now that we have implemented the auto-correct system, how do you evaluate the similarity between two strings? For example: 'waht' and 'what'.*\n",
    "\n",
    "*Also how do you efficiently find the shortest path to go from the word, 'waht' to the word 'what'?*\n",
    "\n",
    "*We will implement a dynamic programming system that will tell you the minimum number of edits required to convert a string into another string.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dynamic Programming breaks a problem down into subproblems which can be combined to form the final solution. Here, given a string source[0..i] and a string target[0..j], we will compute all the combinations of substrings[i, j] and calculate their edit distance. To do this efficiently, we will use a table to maintain the previously computed substrings and use those to calculate larger substrings.*\n",
    "\n",
    "*You have to create a matrix and update each element in the matrix as follows:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Initialization}$$\n",
    "\n",
    "\\begin{align}\n",
    "D[0,0] &= 0 \\\\\n",
    "D[i,0] &= D[i-1,0] + del\\_cost(source[i]) \\tag{eq 03}\\\\\n",
    "D[0,j] &= D[0,j-1] + ins\\_cost(target[j]) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*So converting the source word **play** to the target word **stay**, using an insert cost of one, a delete cost of 1, and replace cost of 2 would give you the following table:*\n",
    "<table style=\"width:20%\">\n",
    "\n",
    "  <tr>\n",
    "    <td> <b> </b>  </td>\n",
    "    <td> <b># </b>  </td>\n",
    "    <td> <b>s </b>  </td>\n",
    "    <td> <b>t </b> </td> \n",
    "    <td> <b>a </b> </td> \n",
    "    <td> <b>y </b> </td> \n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td> <b>  #  </b></td>\n",
    "    <td> 0</td> \n",
    "    <td> 1</td> \n",
    "    <td> 2</td> \n",
    "    <td> 3</td> \n",
    "    <td> 4</td> \n",
    " \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> <b>  p  </b></td>\n",
    "    <td> 1</td> \n",
    " <td> 2</td> \n",
    "    <td> 3</td> \n",
    "    <td> 4</td> \n",
    "   <td> 5</td>\n",
    "  </tr>\n",
    "   \n",
    "  <tr>\n",
    "    <td> <b> l </b></td>\n",
    "    <td>2</td> \n",
    "    <td>3</td> \n",
    "    <td>4</td> \n",
    "    <td>5</td> \n",
    "    <td>6</td>\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td> <b> a </b></td>\n",
    "    <td>3</td> \n",
    "     <td>4</td> \n",
    "     <td>5</td> \n",
    "     <td>4</td>\n",
    "     <td>5</td> \n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td> <b> y </b></td>\n",
    "    <td>4</td> \n",
    "      <td>5</td> \n",
    "     <td>6</td> \n",
    "     <td>5</td>\n",
    "     <td>4</td> \n",
    "  </tr>\n",
    "  \n",
    "\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The operations used in this algorithm are 'insert', 'delete', and 'replace'. These correspond to the functions that we defined earlier: insert_letter(), delete_letter() and replace_letter(). switch_letter() is not used here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The diagram below describes how to initialize the table. Each entry in D[i,j] represents the minimum cost of converting string source[0:i] to string target[0:j]. The first column is initialized to represent the cumulative cost of deleting the source characters to convert string \"EER\" to \"\". The first row is initialized to represent the cumulative cost of inserting the target characters to convert from \"\" to \"NEAR\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='EditDistInit4.PNG' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:1000px;height:400px;\"/> Figure 1 Initializing Distance Matrix</div>     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note that the formula for $D[i,j]$ shown in the image is equivalent to:*\n",
    "\n",
    "\\begin{align}\n",
    " \\\\\n",
    "D[i,j] =min\n",
    "\\begin{cases}\n",
    "D[i-1,j] + del\\_cost\\\\\n",
    "D[i,j-1] + ins\\_cost\\\\\n",
    "D[i-1,j-1] + \\left\\{\\begin{matrix}\n",
    "rep\\_cost; & if src[i]\\neq tar[j]\\\\\n",
    "0 ; & if src[i]=tar[j]\n",
    "\\end{matrix}\\right.\n",
    "\\end{cases}\n",
    "\\tag{5}\n",
    "\\end{align}\n",
    "\n",
    "*The variable `sub_cost` (for substitution cost) is the same as `rep_cost`; replacement cost.  We will stick with the term \"replace\" whenever possible.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='EditDistExample1.PNG' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:1200px;height:400px;\"/> Figure 2 Examples Distance Matrix</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_edit_distance(source, target, ins_cost = 1, del_cost = 1, rep_cost = 2):\n",
    "    '''\n",
    "    Input: \n",
    "        source: a string corresponding to the string you are starting with\n",
    "        target: a string corresponding to the string you want to end with\n",
    "        ins_cost: an integer setting the insert cost\n",
    "        del_cost: an integer setting the delete cost\n",
    "        rep_cost: an integer setting the replace cost\n",
    "    Output:\n",
    "        D: a matrix of len(source)+1 by len(target)+1 containing minimum edit distances\n",
    "        med: the minimum edit distance (med) required to convert the source string to the target\n",
    "    '''\n",
    "    \n",
    "    m = len(source)\n",
    "    n = len(target)\n",
    "    \n",
    "    # initialize cost matrix with zeros and dimensions (m+1, n+1)\n",
    "    D = np.zeros((m+1, n+1), dtype = int)\n",
    "    \n",
    "    # Fill in column 0, from row 1 to row m, both inclusive\n",
    "    for row in range(1, m+1): # Replace None with the proper range\n",
    "        D[row, 0] = D[row -1, 0] + del_cost\n",
    "     \n",
    "    # Fill in row 0, for all columns from 1 to n, both inclusive\n",
    "    for column in range(1, n+1):\n",
    "        D[0, column] = D[0, column - 1] + ins_cost\n",
    "        \n",
    "    # Loop through row 1 to row m, both inclusive\n",
    "    for row in range(1, m+1):\n",
    "        \n",
    "        # Loop through column 1 to column n, both inclusive\n",
    "        for column in range(1, n+1):\n",
    "            \n",
    "            # initialize r_cost to the 'replace' cost that is passed into this function\n",
    "            r_cost = rep_cost\n",
    "            \n",
    "            # check to see if source character at the previous row\n",
    "            # matches the target haracter at the previous column\n",
    "            if source[row - 1] == target[column - 1]:\n",
    "                # Update the replacement cost to 0 if source and\n",
    "                # target are equal\n",
    "                r_cost = 0\n",
    "                \n",
    "            # Update the cost atow, col based on previous entries in the cost matrix\n",
    "            # Refer to the equation calculate for D[i,j] (the mininum of the three calculated)\n",
    "            D[row, column] = min([D[row-1, column] + del_cost, D[row, column-1] + ins_cost, D[row-1, column-1] + r_cost])\n",
    "            \n",
    "    # Set the minimum edit distance with the cost found at row m, column n\n",
    "    \n",
    "    med = D[m, n]\n",
    "    return D, med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum edits:  4 \n",
      "\n",
      "   #  s  t  a  y\n",
      "#  0  1  2  3  4\n",
      "p  1  2  3  4  5\n",
      "l  2  3  4  5  6\n",
      "a  3  4  5  4  5\n",
      "y  4  5  6  5  4\n"
     ]
    }
   ],
   "source": [
    "# testing your implementation \n",
    "source =  'play'\n",
    "target = 'stay'\n",
    "matrix, min_edits = min_edit_distance(source, target)\n",
    "print(\"minimum edits: \",min_edits, \"\\n\")\n",
    "idx = list('#' + source)\n",
    "cols = list('#' + target)\n",
    "df = pd.DataFrame(matrix, index=idx, columns= cols)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum edits:  3 \n",
      "\n",
      "   #  n  e  a  r\n",
      "#  0  1  2  3  4\n",
      "e  1  2  1  2  3\n",
      "e  2  3  2  3  4\n",
      "r  3  4  3  4  3\n"
     ]
    }
   ],
   "source": [
    "# testing your implementation \n",
    "source =  'eer'\n",
    "target = 'near'\n",
    "matrix, min_edits = min_edit_distance(source, target)\n",
    "print(\"minimum edits: \",min_edits, \"\\n\")\n",
    "idx = list(source)\n",
    "idx.insert(0, '#')\n",
    "cols = list(target)\n",
    "cols.insert(0, '#')\n",
    "df = pd.DataFrame(matrix, index=idx, columns= cols)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
